{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4511c1",
   "metadata": {},
   "source": [
    "Prompts\n",
    "A prompt for a language model is a set of instruction or input provided by a user to guid the model's response.\n",
    "Prompts can be defined with **PromptTemplate** and **ChatPromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808d03d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me a funny joke about chicken?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Tell me a {adjective} joke about {topic}?\")\n",
    "result = prompt_template.format(adjective=\"funny\", topic=\"chicken\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b459d",
   "metadata": {},
   "source": [
    "With **ChatPromptTemplate**, it is required to provide an additional parameter called *role*. For example, OpanAi Chat Completion API have System, AI, or Human role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4240175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant. Your name is Alice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am fine, thank you!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is the weather like today?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Your name is {name}\"),\n",
    "        (\"human\", \"Hello, how are you?\"),\n",
    "        (\"assistant\", \"I am fine, thank you!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Alice\", user_input=\"What is the weather like today?\")\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240eb61",
   "metadata": {},
   "source": [
    "**Chat Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1a85cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-Cl5CBeXWsSylLetGAkW8cS5jDDLXh', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--019b064f-57ed-7f91-a8f4-9c755bec0bc7-0', usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    api_key=AZURE_OPENAI_KEY\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9de967",
   "metadata": {},
   "source": [
    "**Completion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e343a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, many Azure services support customer-managed keys (CMK). Customer-managed keys give you full control over encryption keys, allowing you to create, manage, and audit their use. These keys are typically stored in **Azure Key Vault** or **Azure Managed HSM** (Hardware Security Module). \\n\\nHere are some commonly used Azure services that support customer-managed keys:\\n\\n### 1. **Azure Storage Services**\\n   - **Azure Blob Storage**: You can use CMK to encrypt and protect your blob storage data.\\n   - **Azure Files**: Supports CMK for encrypting Azure file shares.\\n   - **Azure Queue Storage**: Data can be encrypted using CMK.\\n\\n### 2. **Azure Disk Encryption**\\n   - Azure Disk Encryption enables you to encrypt virtual machine (VM) disks with CMK. You can use your keys stored in Azure Key Vault for this purpose.\\n\\n### 3. **Azure SQL Database and Managed Instance**\\n   - Both **Azure SQL Database** and **Azure SQL Managed Instance** support the use of CMK for Transparent Data Encryption (TDE).\\n\\n### 4. **Azure Cosmos DB**\\n   - Azure Cosmos DB allows you to use CMK to encrypt data at rest.\\n\\n### 5. **Azure Key Vault**\\n   - Azure Key Vault itself supports CMK and can be used to store keys, secrets, and certificates securely.\\n\\n### 6. **Azure Kubernetes Service (AKS)**\\n   - Encrypt secrets at rest in Etcd using CMK.\\n\\n### 7. **Azure Synapse Analytics**\\n   - Synapse Analytics can leverage CMK for encrypting your data at rest.\\n\\n### 8. **Azure Data Lake Storage**\\n   - Encrypt data at rest using customer-managed keys in Azure Data Lake Storage Gen2.\\n\\n### 9. **Azure Event Hubs**\\n   - You can configure CMK to encrypt data in Azure Event Hubs.\\n\\n### 10. **Azure AI Services and Cognitive Services**\\n   - Azure OpenAI, Azure Cognitive Search, and other cognitive services support customer-managed keys for encrypting data.\\n\\n### 11. **Azure Backup**\\n   - Backups made using Azure Backup can be secured using CMK for encryption.\\n\\n### 12. **Azure Machine Learning**\\n   - Machine Learning data (e.g., datasets, models, etc.) can be encrypted using your own keys stored in Azure Key Vault.\\n\\n### 13. **Azure App Service**\\n   - App Service can use CMK to secure storage accounts tied to your web apps.\\n\\n### 14. **Azure Functions**\\n   - Similarly to App Services, Functions can leverage CMK for storage.\\n\\n---\\n\\n### Benefits of Customer-Managed Keys\\n- **Full Control**: You own and manage the encryption keys.\\n- **Enhanced Security**: Provides fine-grained control over data access and encryption.\\n- **Regulatory Compliance**: Meets compliance requirements where customer control of keys is mandated.\\n- **Key Rotation**: You have full control over key rotation policies.\\n\\nIf you need detailed implementation instructions or information about a specific service, let me know! ðŸ˜Š'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure services support this too?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7087f580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Yes, many Azure services support customer-managed keys (CMK). Customer-managed keys give you full control over encryption keys, allowing you to create, manage, and audit their use. These keys are typically stored in **Azure Key Vault** or **Azure Managed HSM** (Hardware Security Module). \\n\\nHere are some commonly used Azure services that support customer-managed keys:\\n\\n### 1. **Azure Storage Services**\\n   - **Azure Blob Storage**: You can use CMK to encrypt and protect your blob storage data.\\n   - **Azure Files**: Supports CMK for encrypting Azure file shares.\\n   - **Azure Queue Storage**: Data can be encrypted using CMK.\\n\\n### 2. **Azure Disk Encryption**\\n   - Azure Disk Encryption enables you to encrypt virtual machine (VM) disks with CMK. You can use your keys stored in Azure Key Vault for this purpose.\\n\\n### 3. **Azure SQL Database and Managed Instance**\\n   - Both **Azure SQL Database** and **Azure SQL Managed Instance** support the use of CMK for Transparent Data Encryption (TDE).\\n\\n### 4. **Azure Cosmos DB**\\n   - Azure Cosmos DB allows you to use CMK to encrypt data at rest.\\n\\n### 5. **Azure Key Vault**\\n   - Azure Key Vault itself supports CMK and can be used to store keys, secrets, and certificates securely.\\n\\n### 6. **Azure Kubernetes Service (AKS)**\\n   - Encrypt secrets at rest in Etcd using CMK.\\n\\n### 7. **Azure Synapse Analytics**\\n   - Synapse Analytics can leverage CMK for encrypting your data at rest.\\n\\n### 8. **Azure Data Lake Storage**\\n   - Encrypt data at rest using customer-managed keys in Azure Data Lake Storage Gen2.\\n\\n### 9. **Azure Event Hubs**\\n   - You can configure CMK to encrypt data in Azure Event Hubs.\\n\\n### 10. **Azure AI Services and Cognitive Services**\\n   - Azure OpenAI, Azure Cognitive Search, and other cognitive services support customer-managed keys for encrypting data.\\n\\n### 11. **Azure Backup**\\n   - Backups made using Azure Backup can be secured using CMK for encryption.\\n\\n### 12. **Azure Machine Learning**\\n   - Machine Learning data (e.g., datasets, models, etc.) can be encrypted using your own keys stored in Azure Key Vault.\\n\\n### 13. **Azure App Service**\\n   - App Service can use CMK to secure storage accounts tied to your web apps.\\n\\n### 14. **Azure Functions**\\n   - Similarly to App Services, Functions can leverage CMK for storage.\\n\\n---\\n\\n### Benefits of Customer-Managed Keys\\n- **Full Control**: You own and manage the encryption keys.\\n- **Enhanced Security**: Provides fine-grained control over data access and encryption.\\n- **Regulatory Compliance**: Meets compliance requirements where customer control of keys is mandated.\\n- **Key Rotation**: You have full control over key rotation policies.\\n\\nIf you need detailed implementation instructions or information about a specific service, let me know! ðŸ˜Š', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc155650",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "- Language models output text but many times we may want to get more structured information thant just text\n",
    "- An output parser must implement 2 methods:\n",
    "  - *Get format instructions*: A method which returns a string containing instructions for how the output of a language model should be formatted\n",
    "  - *Parse*: A method which takes in a string(assumed to be the response from a language model) and parses it into some structure\n",
    "- LangChain has several built-int output parsers:\n",
    "  - List parser\n",
    "  - Datetime parser\n",
    "  - Enum parser\n",
    "  - ConvoOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d2ea7",
   "metadata": {},
   "source": [
    "**Chains**\n",
    "- Using an LLM in a single step is fine for simple applications but more complex applications require chaining LLMs - either with each other LLM or with other components.\n",
    "- There are several chain types:\n",
    "  - LLM chain: Is the most common type of chaining in LLM application\n",
    "  - Router chain: Route to different operations based on user input\n",
    "  - Sequential chain: Combine multiple LLM chain into a pipeline\n",
    "  - Transformation chain: Transform inputs with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca2554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a robot joke for you:\\n\\nWhy did the robot go on a diet?  \\nBecause he had a byte problem! ðŸ¤–\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "# Use LLM Chain\n",
    "prompt_template = \"\"\"Tell me a joke about {topic}?\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "llm_chain = ChatPromptTemplate.from_template(prompt_template) | llm\n",
    "result = llm_chain.invoke({\"topic\": \"robot\"})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985c68a",
   "metadata": {},
   "source": [
    "**Tools**\n",
    "- Tools are interfaces that an agent, chain, or LLM can use to interact with the world\n",
    "- They combine a few things:\n",
    "  - The name of the tool\n",
    "  - A description of what the tool does\n",
    "  - JSON schema of the inputs to the tool\n",
    "  - The function to call\n",
    "  - Whether the result of the tool should be returned directly to the user\n",
    "- Tools can be used to:\n",
    "  - Search the web\n",
    "  - Query databases\n",
    "  - Perform calculations\n",
    "  - Call APIs\n",
    "  - Execute custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548081e",
   "metadata": {},
   "source": [
    "**Creating a Custom Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d41d1ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: multiply\n",
      "Tool description: Multiply two numbers together.\n",
      "Tool args: {'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}\n",
      "Result: 15.0\n",
      "\n",
      "Add result: 17.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Test the tools\n",
    "print(f\"Tool name: {multiply.name}\")\n",
    "print(f\"Tool description: {multiply.description}\")\n",
    "print(f\"Tool args: {multiply.args}\")\n",
    "print(f\"Result: {multiply.invoke({'a': 5, 'b': 3})}\")\n",
    "print()\n",
    "print(f\"Add result: {add.invoke({'a': 10, 'b': 7})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb42b3",
   "metadata": {},
   "source": [
    "**Using Tools with LLM (Function Calling)**\n",
    "- Modern LLMs can decide when and how to use tools\n",
    "- The LLM analyzes the user's request and determines which tool to call\n",
    "- This is also known as \"function calling\" or \"tool calling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503df728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 75, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-Cl5CRV5iR9PiesIsFiJt3eXG6eeWY', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}} id='lc_run--019b064f-9ba7-7850-9424-ecf420809ceb-0' tool_calls=[{'name': 'get_weather', 'args': {'city': 'Paris'}, 'id': 'call_968JmVVQrQqKoRblapGtagnD', 'type': 'tool_call'}] usage_metadata={'input_tokens': 75, 'output_tokens': 15, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Tool calls: [{'name': 'get_weather', 'args': {'city': 'Paris'}, 'id': 'call_968JmVVQrQqKoRblapGtagnD', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a given city.\"\"\"\n",
    "    # In a real scenario, this would call a weather API\n",
    "    return f\"The weather in {city} is sunny with a temperature of 72Â°F\"\n",
    "\n",
    "@tool\n",
    "def calculate_age(birth_year: int) -> int:\n",
    "    \"\"\"Calculate age based on birth year.\"\"\"\n",
    "    from datetime import datetime\n",
    "    current_year = datetime.now().year\n",
    "    return current_year - birth_year\n",
    "\n",
    "# Bind tools to the LLM\n",
    "tools = [get_weather, calculate_age]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# The LLM will decide which tool to use based on the user's question\n",
    "response = llm_with_tools.invoke(\"What's the weather like in Paris?\")\n",
    "print(response)\n",
    "print()\n",
    "print(\"Tool calls:\", response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bf80d",
   "metadata": {},
   "source": [
    "**Executing Tool Calls**\n",
    "- When the LLM decides to use a tool, it returns a tool call\n",
    "- We need to execute the tool and return the result back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47bb6c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: get_weather\n",
      "Arguments: {'city': 'Tokyo'}\n",
      "Result: The weather in Tokyo is sunny with a temperature of 72Â°F\n",
      "\n",
      "Final Response: The weather in Tokyo is sunny with a temperature of 72Â°F.\n",
      "\n",
      "Final Response: The weather in Tokyo is sunny with a temperature of 72Â°F.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "# Get the LLM's response with tool call\n",
    "messages = [HumanMessage(content=\"What's the weather in Tokyo?\")]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "# Check if the LLM wants to use a tool\n",
    "if ai_msg.tool_calls:\n",
    "    # Execute the tool\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        \n",
    "        # Find and execute the matching tool\n",
    "        selected_tool = {tool.name: tool for tool in tools}[tool_name]\n",
    "        tool_output = selected_tool.invoke(tool_args)\n",
    "        \n",
    "        print(f\"Tool: {tool_name}\")\n",
    "        print(f\"Arguments: {tool_args}\")\n",
    "        print(f\"Result: {tool_output}\")\n",
    "        \n",
    "        # Continue conversation with tool result\n",
    "        messages.append(ai_msg)\n",
    "        messages.append(ToolMessage(content=str(tool_output), tool_call_id=tool_call[\"id\"]))\n",
    "        \n",
    "        # Get final response from LLM\n",
    "        final_response = llm_with_tools.invoke(messages)\n",
    "        print(f\"\\nFinal Response: {final_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43c6a3",
   "metadata": {},
   "source": [
    "**Built-in Tools**\n",
    "- LangChain provides many pre-built tools for common tasks\n",
    "- Examples include: Wikipedia search, DuckDuckGo search, Python REPL, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f38ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level programming language\n"
     ]
    }
   ],
   "source": [
    "# Example: Using Wikipedia tool (requires: pip install wikipedia)\n",
    "# Uncomment to use:\n",
    "# from langchain_community.tools import WikipediaQueryRun\n",
    "# from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "# result = wikipedia.invoke(\"LangChain\")\n",
    "# print(result)\n",
    "\n",
    "# For now, let's create a simple search tool\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"Search a database for information.\"\"\"\n",
    "    # Mock implementation\n",
    "    database = {\n",
    "        \"python\": \"Python is a high-level programming language\",\n",
    "        \"langchain\": \"LangChain is a framework for developing LLM applications\",\n",
    "        \"azure\": \"Azure is Microsoft's cloud computing platform\"\n",
    "    }\n",
    "    return database.get(query.lower(), \"No information found\")\n",
    "\n",
    "result = search_database.invoke({\"query\": \"python\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
